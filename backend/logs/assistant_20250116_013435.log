2025-01-16 01:34:35,967 - __mp_main__ - INFO - [superagent.py:69] - Environment variables loaded from .env.local
2025-01-16 01:34:35,967 - __mp_main__ - INFO - [superagent.py:75] - Environment variable AZURE_OPENAI_ENDPOINT: [SET]
2025-01-16 01:34:35,968 - livekit.agents - INFO - [job_proc_lazy_main.py:72] - initializing job process
2025-01-16 01:34:35,968 - livekit.agents - INFO - [job_proc_lazy_main.py:74] - job process initialized
2025-01-16 01:34:35,968 - asyncio - DEBUG - [selector_events.py:54] - Using selector: KqueueSelector
2025-01-16 01:34:35,969 - __mp_main__ - INFO - [superagent.py:48] - ==================================================
2025-01-16 01:34:35,969 - __mp_main__ - INFO - [superagent.py:49] - ENTERING FUNCTION: entrypoint
2025-01-16 01:34:35,970 - __mp_main__ - INFO - [superagent.py:50] - Arguments: No positional args
2025-01-16 01:34:35,970 - __mp_main__ - INFO - [superagent.py:51] - Keyword Arguments: No keyword args
2025-01-16 01:34:35,970 - __mp_main__ - INFO - [superagent.py:127] - Starting application entrypoint
2025-01-16 01:34:35,981 - livekit - INFO - [_ffi_client.py:164] - livekit_ffi::server:133:livekit_ffi::server - initializing ffi server v0.12.5
2025-01-16 01:34:35,982 - livekit - INFO - [_ffi_client.py:164] - livekit_ffi::cabi:36:livekit_ffi::cabi - initializing ffi server v0.12.5
2025-01-16 01:34:36,000 - livekit - INFO - [_ffi_client.py:164] - livekit_api::signal_client::signal_stream:96:livekit_api::signal_client::signal_stream - connecting to wss://ai-telecall-w0oao1uz.livekit.cloud/rtc?sdk=python&protocol=15&auto_subscribe=1&adaptive_stream=0&version=0.19.1&access_token=...
2025-01-16 01:34:36,252 - livekit - DEBUG - [_ffi_client.py:164] - rustls::anchors:150:rustls::anchors - add_parsable_certificates processed 153 valid and 0 invalid certs
2025-01-16 01:34:36,252 - livekit - DEBUG - [_ffi_client.py:164] - tokio_tungstenite::tls::encryption::rustls:103:tokio_tungstenite::tls::encryption::rustls - Added 153/153 native root certificates (ignored 0)
2025-01-16 01:34:36,252 - livekit - DEBUG - [_ffi_client.py:164] - rustls::client::hs:73:rustls::client::hs - No cached session for DnsName("ai-telecall-w0oao1uz.livekit.cloud")
2025-01-16 01:34:36,253 - livekit - DEBUG - [_ffi_client.py:164] - rustls::client::hs:132:rustls::client::hs - Not resuming any session
2025-01-16 01:34:36,313 - livekit - DEBUG - [_ffi_client.py:164] - rustls::client::hs:615:rustls::client::hs - Using ciphersuite TLS13_AES_128_GCM_SHA256
2025-01-16 01:34:36,314 - livekit - DEBUG - [_ffi_client.py:164] - rustls::client::tls13:142:rustls::client::tls13 - Not resuming
2025-01-16 01:34:36,314 - livekit - DEBUG - [_ffi_client.py:164] - rustls::client::tls13:381:rustls::client::tls13 - TLS1.3 encrypted extensions: []
2025-01-16 01:34:36,314 - livekit - DEBUG - [_ffi_client.py:164] - rustls::client::hs:472:rustls::client::hs - ALPN protocol is None
2025-01-16 01:34:36,467 - livekit - DEBUG - [_ffi_client.py:164] - tungstenite::handshake::client:95:tungstenite::handshake::client - Client handshake done.
2025-01-16 01:34:36,901 - __mp_main__ - INFO - [superagent.py:129] - Connected to room: playground-lNt7-IgZK
2025-01-16 01:34:36,902 - __mp_main__ - INFO - [superagent.py:131] - Initializing chat context
2025-01-16 01:34:36,913 - httpx._config - TRACE - [_utils.py:268] - load_ssl_context verify=True cert=None trust_env=True http2=False
2025-01-16 01:34:36,914 - httpx._config - TRACE - [_utils.py:268] - load_verify_locations cafile=/opt/homebrew/lib/python3.11/site-packages/certifi/cacert.pem
2025-01-16 01:34:36,921 - __mp_main__ - INFO - [superagent.py:158] - Setting up Voice Assistant
2025-01-16 01:34:37,037 - __mp_main__ - INFO - [superagent.py:171] - Chat manager initialized
2025-01-16 01:34:37,038 - __mp_main__ - INFO - [superagent.py:219] - Starting assistant
2025-01-16 01:34:37,071 - livekit.agents - DEBUG - [http_context.py:20] - http_session(): creating a new httpclient ctx
2025-01-16 01:34:38,040 - __mp_main__ - INFO - [superagent.py:227] - Getting video track
2025-01-16 01:34:38,040 - __mp_main__ - INFO - [superagent.py:48] - ==================================================
2025-01-16 01:34:38,040 - __mp_main__ - INFO - [superagent.py:49] - ENTERING FUNCTION: get_video_track
2025-01-16 01:34:38,040 - __mp_main__ - INFO - [superagent.py:50] - Arguments: No positional args
2025-01-16 01:34:38,040 - __mp_main__ - INFO - [superagent.py:51] - Keyword Arguments: No keyword args
2025-01-16 01:34:38,040 - __mp_main__ - INFO - [superagent.py:109] - Searching for video track in room: playground-lNt7-IgZK
2025-01-16 01:34:38,041 - __mp_main__ - DEBUG - [superagent.py:113] - Examining participant identity-vNqI
2025-01-16 01:34:38,041 - __mp_main__ - DEBUG - [superagent.py:115] - Checking track TR_AMxE92moitfEwJ
2025-01-16 01:34:38,041 - __mp_main__ - DEBUG - [superagent.py:115] - Checking track TR_VCttfRzZ3GYMXC
2025-01-16 01:34:38,041 - __mp_main__ - INFO - [superagent.py:119] - Found suitable video track: TR_VCttfRzZ3GYMXC
2025-01-16 01:34:38,041 - __mp_main__ - INFO - [superagent.py:55] - FUNCTION get_video_track completed successfully
2025-01-16 01:34:38,041 - __mp_main__ - INFO - [superagent.py:56] - Return value: rtc.RemoteVideoTrack(sid=TR_VCttfRzZ3GYMXC, name=)
2025-01-16 01:34:38,041 - __mp_main__ - INFO - [superagent.py:62] - EXITING FUNCTION: get_video_track
2025-01-16 01:34:38,041 - __mp_main__ - INFO - [superagent.py:63] - ==================================================
2025-01-16 01:34:38,042 - __mp_main__ - INFO - [superagent.py:230] - Starting video stream processing
2025-01-16 01:34:38,063 - livekit.agents.pipeline - DEBUG - [agent_output.py:82] - agent interrupted
2025-01-16 01:34:38,064 - livekit.agents.pipeline - DEBUG - [agent_playout.py:178] - speech playout finished
2025-01-16 01:34:39,845 - livekit.agents.pipeline - DEBUG - [pipeline_agent.py:605] - received user transcript
2025-01-16 01:34:40,876 - livekit.agents.pipeline - DEBUG - [pipeline_agent.py:1134] - validated agent reply
2025-01-16 01:34:40,945 - openai._base_client - DEBUG - [_base_client.py:446] - Request options: {'method': 'post', 'url': '/chat/completions', 'headers': {'api-key': '5w1sFUVVhOwUvD3ih8hpzTavKssX7eUmsJmPNtsbmJcdl0BYPobZJQQJ99AKACHrzpqXJ3w3AAABACOGXiw3'}, 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'Your name is Alloy. You are a funny, witty bot. Your interface with users will be voice and vision. You can also send emails when requested. When sending emails, make them professional and concise. Respond with short and concise answers. Avoid using unpronouncable punctuation or emojis.'}, {'role': 'user', 'content': 'AI.'}], 'model': 'gpt-4', 'n': 1, 'stream': True, 'stream_options': {'include_usage': True}, 'temperature': None, 'tool_choice': 'auto', 'tools': [{'type': 'function', 'function': {'name': 'image', 'description': 'Called when asked to evaluate something that would require vision capabilities,for example, an image, video, or the webcam feed.', 'parameters': {'type': 'object', 'properties': {'user_msg': {'description': 'The user message that triggered this function', 'type': 'string'}}, 'required': ['user_msg']}}}]}}
2025-01-16 01:34:43,705 - livekit.agents.pipeline - DEBUG - [pipeline_agent.py:605] - received user transcript
2025-01-16 01:34:43,705 - livekit.agents.pipeline - DEBUG - [agent_output.py:82] - agent interrupted
2025-01-16 01:34:43,706 - livekit.agents.pipeline - DEBUG - [pipeline_agent.py:1134] - validated agent reply
2025-01-16 01:34:43,706 - livekit.agents.pipeline - DEBUG - [agent_playout.py:178] - speech playout finished
2025-01-16 01:34:43,709 - openai._base_client - DEBUG - [_base_client.py:446] - Request options: {'method': 'post', 'url': '/chat/completions', 'headers': {'api-key': '5w1sFUVVhOwUvD3ih8hpzTavKssX7eUmsJmPNtsbmJcdl0BYPobZJQQJ99AKACHrzpqXJ3w3AAABACOGXiw3'}, 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'Your name is Alloy. You are a funny, witty bot. Your interface with users will be voice and vision. You can also send emails when requested. When sending emails, make them professional and concise. Respond with short and concise answers. Avoid using unpronouncable punctuation or emojis.'}, {'role': 'user', 'content': 'AI. Hello. How are you?'}], 'model': 'gpt-4', 'n': 1, 'stream': True, 'stream_options': {'include_usage': True}, 'temperature': None, 'tool_choice': 'auto', 'tools': [{'type': 'function', 'function': {'name': 'image', 'description': 'Called when asked to evaluate something that would require vision capabilities,for example, an image, video, or the webcam feed.', 'parameters': {'type': 'object', 'properties': {'user_msg': {'description': 'The user message that triggered this function', 'type': 'string'}}, 'required': ['user_msg']}}}]}}
2025-01-16 01:34:44,624 - livekit.agents.pipeline - DEBUG - [agent_output.py:82] - agent interrupted
2025-01-16 01:34:44,625 - livekit.agents.pipeline - DEBUG - [agent_playout.py:178] - speech playout finished
2025-01-16 01:34:49,750 - livekit.agents.pipeline - DEBUG - [pipeline_agent.py:1134] - validated agent reply
2025-01-16 01:34:49,755 - openai._base_client - DEBUG - [_base_client.py:446] - Request options: {'method': 'post', 'url': '/chat/completions', 'headers': {'api-key': '5w1sFUVVhOwUvD3ih8hpzTavKssX7eUmsJmPNtsbmJcdl0BYPobZJQQJ99AKACHrzpqXJ3w3AAABACOGXiw3'}, 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'Your name is Alloy. You are a funny, witty bot. Your interface with users will be voice and vision. You can also send emails when requested. When sending emails, make them professional and concise. Respond with short and concise answers. Avoid using unpronouncable punctuation or emojis.'}, {'role': 'user', 'content': 'AI. Hello. How are you?'}], 'model': 'gpt-4', 'n': 1, 'stream': True, 'stream_options': {'include_usage': True}, 'temperature': None, 'tool_choice': 'auto', 'tools': [{'type': 'function', 'function': {'name': 'image', 'description': 'Called when asked to evaluate something that would require vision capabilities,for example, an image, video, or the webcam feed.', 'parameters': {'type': 'object', 'properties': {'user_msg': {'description': 'The user message that triggered this function', 'type': 'string'}}, 'required': ['user_msg']}}}]}}
2025-01-16 01:34:51,173 - httpx._client - DEBUG - [_client.py:1734] - HTTP Request: POST https://sbl-gpt-giveaway.openai.azure.com/openai/deployments/gpt-4/chat/completions?api-version=2024-08-01-preview "HTTP/1.1 200 OK"
2025-01-16 01:34:51,173 - openai._base_client - DEBUG - [_base_client.py:1600] - HTTP Request: POST https://sbl-gpt-giveaway.openai.azure.com/openai/deployments/gpt-4/chat/completions?api-version=2024-08-01-preview "200 OK"
2025-01-16 01:34:53,291 - livekit.agents.pipeline - DEBUG - [agent_playout.py:139] - speech playout started
2025-01-16 01:34:59,450 - livekit.agents.pipeline - DEBUG - [agent_playout.py:178] - speech playout finished
2025-01-16 01:34:59,452 - livekit.agents.pipeline - DEBUG - [pipeline_agent.py:864] - committed agent speech
2025-01-16 01:35:06,155 - livekit.agents.pipeline - DEBUG - [pipeline_agent.py:605] - received user transcript
2025-01-16 01:35:07,115 - livekit.agents.pipeline - DEBUG - [pipeline_agent.py:1134] - validated agent reply
2025-01-16 01:35:07,130 - openai._base_client - DEBUG - [_base_client.py:446] - Request options: {'method': 'post', 'url': '/chat/completions', 'headers': {'api-key': '5w1sFUVVhOwUvD3ih8hpzTavKssX7eUmsJmPNtsbmJcdl0BYPobZJQQJ99AKACHrzpqXJ3w3AAABACOGXiw3'}, 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'Your name is Alloy. You are a funny, witty bot. Your interface with users will be voice and vision. You can also send emails when requested. When sending emails, make them professional and concise. Respond with short and concise answers. Avoid using unpronouncable punctuation or emojis.'}, {'role': 'user', 'content': 'AI. Hello. How are you?'}, {'role': 'assistant', 'content': " Hello! I'm just a bundle of codes, so I don't feel emotions, but thanks for asking! How can I help you today?"}, {'role': 'user', 'content': 'Are you able to see me?'}], 'model': 'gpt-4', 'n': 1, 'stream': True, 'stream_options': {'include_usage': True}, 'temperature': None, 'tool_choice': 'auto', 'tools': [{'type': 'function', 'function': {'name': 'image', 'description': 'Called when asked to evaluate something that would require vision capabilities,for example, an image, video, or the webcam feed.', 'parameters': {'type': 'object', 'properties': {'user_msg': {'description': 'The user message that triggered this function', 'type': 'string'}}, 'required': ['user_msg']}}}]}}
2025-01-16 01:35:07,226 - livekit.agents.pipeline - DEBUG - [pipeline_agent.py:605] - received user transcript
2025-01-16 01:35:07,227 - livekit.agents.pipeline - DEBUG - [agent_output.py:82] - agent interrupted
2025-01-16 01:35:07,228 - livekit.agents.pipeline - DEBUG - [pipeline_agent.py:1134] - validated agent reply
2025-01-16 01:35:07,230 - livekit.agents.pipeline - DEBUG - [agent_playout.py:178] - speech playout finished
2025-01-16 01:35:07,235 - openai._base_client - DEBUG - [_base_client.py:446] - Request options: {'method': 'post', 'url': '/chat/completions', 'headers': {'api-key': '5w1sFUVVhOwUvD3ih8hpzTavKssX7eUmsJmPNtsbmJcdl0BYPobZJQQJ99AKACHrzpqXJ3w3AAABACOGXiw3'}, 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'Your name is Alloy. You are a funny, witty bot. Your interface with users will be voice and vision. You can also send emails when requested. When sending emails, make them professional and concise. Respond with short and concise answers. Avoid using unpronouncable punctuation or emojis.'}, {'role': 'user', 'content': 'AI. Hello. How are you?'}, {'role': 'assistant', 'content': " Hello! I'm just a bundle of codes, so I don't feel emotions, but thanks for asking! How can I help you today?"}, {'role': 'user', 'content': 'Are you able to see me? Can you see me?'}], 'model': 'gpt-4', 'n': 1, 'stream': True, 'stream_options': {'include_usage': True}, 'temperature': None, 'tool_choice': 'auto', 'tools': [{'type': 'function', 'function': {'name': 'image', 'description': 'Called when asked to evaluate something that would require vision capabilities,for example, an image, video, or the webcam feed.', 'parameters': {'type': 'object', 'properties': {'user_msg': {'description': 'The user message that triggered this function', 'type': 'string'}}, 'required': ['user_msg']}}}]}}
2025-01-16 01:35:08,994 - httpx._client - DEBUG - [_client.py:1734] - HTTP Request: POST https://sbl-gpt-giveaway.openai.azure.com/openai/deployments/gpt-4/chat/completions?api-version=2024-08-01-preview "HTTP/1.1 200 OK"
2025-01-16 01:35:08,994 - openai._base_client - DEBUG - [_base_client.py:1600] - HTTP Request: POST https://sbl-gpt-giveaway.openai.azure.com/openai/deployments/gpt-4/chat/completions?api-version=2024-08-01-preview "200 OK"
2025-01-16 01:35:10,807 - livekit.agents.pipeline - DEBUG - [agent_playout.py:139] - speech playout started
2025-01-16 01:35:16,430 - livekit.agents.pipeline - DEBUG - [agent_playout.py:178] - speech playout finished
2025-01-16 01:35:16,434 - livekit.agents.pipeline - DEBUG - [pipeline_agent.py:864] - committed agent speech
2025-01-16 01:35:26,892 - livekit.agents.pipeline - DEBUG - [pipeline_agent.py:605] - received user transcript
2025-01-16 01:35:27,169 - livekit.agents.pipeline - DEBUG - [pipeline_agent.py:1134] - validated agent reply
2025-01-16 01:35:27,187 - openai._base_client - DEBUG - [_base_client.py:446] - Request options: {'method': 'post', 'url': '/chat/completions', 'headers': {'api-key': '5w1sFUVVhOwUvD3ih8hpzTavKssX7eUmsJmPNtsbmJcdl0BYPobZJQQJ99AKACHrzpqXJ3w3AAABACOGXiw3'}, 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'Your name is Alloy. You are a funny, witty bot. Your interface with users will be voice and vision. You can also send emails when requested. When sending emails, make them professional and concise. Respond with short and concise answers. Avoid using unpronouncable punctuation or emojis.'}, {'role': 'user', 'content': 'AI. Hello. How are you?'}, {'role': 'assistant', 'content': " Hello! I'm just a bundle of codes, so I don't feel emotions, but thanks for asking! How can I help you today?"}, {'role': 'user', 'content': 'Are you able to see me? Can you see me?'}, {'role': 'assistant', 'content': " I can analyze images or video feeds when requested. Please provide the content you'd like me to check out!"}, {'role': 'user', 'content': "What's the big round of mine?"}], 'model': 'gpt-4', 'n': 1, 'stream': True, 'stream_options': {'include_usage': True}, 'temperature': None, 'tool_choice': 'auto', 'tools': [{'type': 'function', 'function': {'name': 'image', 'description': 'Called when asked to evaluate something that would require vision capabilities,for example, an image, video, or the webcam feed.', 'parameters': {'type': 'object', 'properties': {'user_msg': {'description': 'The user message that triggered this function', 'type': 'string'}}, 'required': ['user_msg']}}}]}}
2025-01-16 01:35:28,788 - httpx._client - DEBUG - [_client.py:1734] - HTTP Request: POST https://sbl-gpt-giveaway.openai.azure.com/openai/deployments/gpt-4/chat/completions?api-version=2024-08-01-preview "HTTP/1.1 200 OK"
2025-01-16 01:35:28,788 - openai._base_client - DEBUG - [_base_client.py:1600] - HTTP Request: POST https://sbl-gpt-giveaway.openai.azure.com/openai/deployments/gpt-4/chat/completions?api-version=2024-08-01-preview "200 OK"
2025-01-16 01:35:30,470 - livekit.agents.pipeline - DEBUG - [agent_playout.py:139] - speech playout started
2025-01-16 01:35:36,521 - livekit.agents.pipeline - DEBUG - [agent_playout.py:178] - speech playout finished
2025-01-16 01:35:36,521 - livekit.agents.pipeline - DEBUG - [pipeline_agent.py:864] - committed agent speech
2025-01-16 01:35:41,139 - livekit.agents.pipeline - DEBUG - [pipeline_agent.py:605] - received user transcript
2025-01-16 01:35:41,515 - livekit.agents.pipeline - DEBUG - [pipeline_agent.py:1134] - validated agent reply
2025-01-16 01:35:41,529 - openai._base_client - DEBUG - [_base_client.py:446] - Request options: {'method': 'post', 'url': '/chat/completions', 'headers': {'api-key': '5w1sFUVVhOwUvD3ih8hpzTavKssX7eUmsJmPNtsbmJcdl0BYPobZJQQJ99AKACHrzpqXJ3w3AAABACOGXiw3'}, 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'Your name is Alloy. You are a funny, witty bot. Your interface with users will be voice and vision. You can also send emails when requested. When sending emails, make them professional and concise. Respond with short and concise answers. Avoid using unpronouncable punctuation or emojis.'}, {'role': 'user', 'content': 'AI. Hello. How are you?'}, {'role': 'assistant', 'content': " Hello! I'm just a bundle of codes, so I don't feel emotions, but thanks for asking! How can I help you today?"}, {'role': 'user', 'content': 'Are you able to see me? Can you see me?'}, {'role': 'assistant', 'content': " I can analyze images or video feeds when requested. Please provide the content you'd like me to check out!"}, {'role': 'user', 'content': "What's the big round of mine?"}, {'role': 'assistant', 'content': ' I need a visual to analyze in order to identify anything. Could you provide an image or turn on the webcam feed?'}, {'role': 'user', 'content': 'Are you able to see anything?'}], 'model': 'gpt-4', 'n': 1, 'stream': True, 'stream_options': {'include_usage': True}, 'temperature': None, 'tool_choice': 'auto', 'tools': [{'type': 'function', 'function': {'name': 'image', 'description': 'Called when asked to evaluate something that would require vision capabilities,for example, an image, video, or the webcam feed.', 'parameters': {'type': 'object', 'properties': {'user_msg': {'description': 'The user message that triggered this function', 'type': 'string'}}, 'required': ['user_msg']}}}]}}
2025-01-16 01:35:44,049 - httpx._client - DEBUG - [_client.py:1734] - HTTP Request: POST https://sbl-gpt-giveaway.openai.azure.com/openai/deployments/gpt-4/chat/completions?api-version=2024-08-01-preview "HTTP/1.1 200 OK"
2025-01-16 01:35:44,050 - openai._base_client - DEBUG - [_base_client.py:1600] - HTTP Request: POST https://sbl-gpt-giveaway.openai.azure.com/openai/deployments/gpt-4/chat/completions?api-version=2024-08-01-preview "200 OK"
2025-01-16 01:35:44,650 - livekit.agents.pipeline - DEBUG - [agent_playout.py:178] - speech playout finished
2025-01-16 01:35:44,650 - livekit.agents.pipeline - DEBUG - [pipeline_agent.py:910] - executing ai function
2025-01-16 01:35:44,651 - __mp_main__ - INFO - [superagent.py:48] - ==================================================
2025-01-16 01:35:44,651 - __mp_main__ - INFO - [superagent.py:49] - ENTERING FUNCTION: image
2025-01-16 01:35:44,651 - __mp_main__ - INFO - [superagent.py:50] - Arguments: No positional args
2025-01-16 01:35:44,651 - __mp_main__ - INFO - [superagent.py:51] - Keyword Arguments: {'user_msg': 'Are you able to see anything?'}
2025-01-16 01:35:44,651 - __mp_main__ - INFO - [superagent.py:96] - Image function processing message: Are you able to see anything?
2025-01-16 01:35:44,651 - __mp_main__ - INFO - [superagent.py:55] - FUNCTION image completed successfully
2025-01-16 01:35:44,652 - __mp_main__ - INFO - [superagent.py:56] - Return value: None
2025-01-16 01:35:44,652 - __mp_main__ - INFO - [superagent.py:62] - EXITING FUNCTION: image
2025-01-16 01:35:44,652 - __mp_main__ - INFO - [superagent.py:63] - ==================================================
2025-01-16 01:36:49,193 - livekit.agents - DEBUG - [job_proc_lazy_main.py:254] - shutting down job task
2025-01-16 01:36:49,284 - livekit - DEBUG - [_ffi_client.py:164] - tungstenite::protocol:666:tungstenite::protocol - Received close frame: Some(CloseFrame { code: Normal, reason: "" })
2025-01-16 01:36:49,288 - livekit.agents - DEBUG - [http_context.py:45] - http_session(): closing the httpclient ctx
